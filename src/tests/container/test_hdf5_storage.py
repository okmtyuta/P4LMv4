#!/usr/bin/env python3
"""
Hdf5Storage ã®æ©Ÿèƒ½è»¸ãƒ†ã‚¹ãƒˆ
"""

import tempfile
from pathlib import Path
from typing import Dict

import h5py
import numpy as np
import pytest
import torch

from src.modules.container.hdf5_storage import Hdf5Storage


class TestSerialization:
    """HDF5ã¸ã®æ›¸ãè¾¼ã¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""

    def test_simple_data_serialization(self):
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        data = {
            "integer": 42,
            "float_val": 3.14159,
            "boolean": True,
            "string": "Hello HDF5",
            "none_value": None,
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãä½œæˆã•ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
            with h5py.File(tmp_path, "r") as f:
                assert "integer" in f
                assert "float_val" in f
                assert "boolean" in f
                assert "string" in f
                assert "none_value" in f
                assert f["integer"][()] == 42
                assert f["string"].asstr()[()] == "Hello HDF5"
        finally:
            tmp_path.unlink()

    def test_numpy_array_serialization(self):
        """NumPyé…åˆ—ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        data = {
            "int_array": np.array([1, 2, 3, 4, 5]),
            "float_array": np.array([1.1, 2.2, 3.3]),
            "bool_array": np.array([True, False, True]),
            "2d_array": np.array([[1, 2], [3, 4]]),
            "empty_array": np.array([]),
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            # é…åˆ—ã®å½¢çŠ¶ã¨å†…å®¹ã‚’ç¢ºèª
            with h5py.File(tmp_path, "r") as f:
                np.testing.assert_array_equal(f["int_array"][...], [1, 2, 3, 4, 5])
                np.testing.assert_array_almost_equal(f["float_array"][...], [1.1, 2.2, 3.3])
                assert f["2d_array"].shape == (2, 2)
                assert f["empty_array"].shape == (0,)
        finally:
            tmp_path.unlink()

    def test_torch_tensor_serialization(self):
        """PyTorchãƒ†ãƒ³ã‚½ãƒ«ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        data = {
            "tensor_1d": torch.tensor([1.0, 2.0, 3.0]),
            "tensor_2d": torch.tensor([[1, 2], [3, 4]]),
            "tensor_float32": torch.tensor([1.0, 2.0], dtype=torch.float32),
            "tensor_int64": torch.tensor([1, 2, 3], dtype=torch.int64),
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            # ãƒ†ãƒ³ã‚½ãƒ«ãƒãƒ¼ã‚«ãƒ¼ã¨å‹æƒ…å ±ã‚’ç¢ºèª
            with h5py.File(tmp_path, "r") as f:
                assert bool(f["tensor_1d"].attrs.get("__TORCH__")) is True
                assert "float32" in f["tensor_float32"].attrs.get("__TORCH_DTYPE__", "")
                np.testing.assert_array_equal(f["tensor_2d"][...], [[1, 2], [3, 4]])
        finally:
            tmp_path.unlink()

    def test_list_serialization(self):
        """ãƒªã‚¹ãƒˆ/ã‚¿ãƒ—ãƒ«ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        data = {
            "empty_list": [],
            "number_list": [1, 2, 3, 4, 5],
            "string_list": ["apple", "banana", "cherry"],
            "mixed_list": [1, "hello", 3.14],
            "nested_list": [[1, 2], [3, 4], [5, 6]],
            "tuple_data": (10, 20, 30),
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                # ç©ºãƒªã‚¹ãƒˆã¯ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã‚‹
                assert f["empty_list"].attrs.get("__TYPE__") == "list"
                assert f["empty_list"].attrs.get("__LENGTH__") == 0

                # æ•°å€¤ãƒªã‚¹ãƒˆã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ä¿å­˜ã•ã‚Œã‚‹
                np.testing.assert_array_equal(f["number_list"][...], [1, 2, 3, 4, 5])

                # æ–‡å­—åˆ—ãƒªã‚¹ãƒˆã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ä¿å­˜ã•ã‚Œã‚‹
                str_array = f["string_list"].asstr()[...]
                assert list(str_array) == ["apple", "banana", "cherry"]

                # æ··åˆãƒªã‚¹ãƒˆã¯ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã‚‹
                assert f["mixed_list"].attrs.get("__TYPE__") == "list"
                assert "0" in f["mixed_list"]
                assert "1" in f["mixed_list"]
        finally:
            tmp_path.unlink()

    def test_bytes_serialization(self):
        """ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        data = {
            "single_bytes": b"hello world",
            "bytearray_data": bytearray(b"test data"),
            "bytes_list": [b"first", b"second", b"third"],
            "empty_bytes": b"",
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚«ãƒ¼ã‚’ç¢ºèª
                assert bool(f["single_bytes"].attrs.get("__BYTES__")) is True
                assert bool(f["bytearray_data"].attrs.get("__BYTES__")) is True

                # ãƒã‚¤ãƒˆãƒªã‚¹ãƒˆã¯ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã—ã¦ä¿å­˜ã•ã‚Œã‚‹
                assert f["bytes_list"].attrs.get("__TYPE__") == "list"
                assert f["bytes_list"]["0"].attrs.get("__ELEM_TYPE__") == "bytes_uint8"
        finally:
            tmp_path.unlink()

    def test_nested_dict_serialization(self):
        """ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        data = {
            "level1": {
                "level2": {
                    "level3": {
                        "deep_value": 42,
                        "deep_array": np.array([1, 2, 3]),
                    }
                },
                "sibling": "value",
            },
            "metadata": {"version": "1.0", "author": "test"},
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ ã‚’ç¢ºèª
                assert f["level1/level2/level3/deep_value"][()] == 42
                np.testing.assert_array_equal(f["level1/level2/level3/deep_array"][...], [1, 2, 3])
                assert f["level1/sibling"].asstr()[()] == "value"
                assert f["metadata/version"].asstr()[()] == "1.0"
        finally:
            tmp_path.unlink()


class TestDeserialization:
    """HDF5ã‹ã‚‰ã®èª­ã¿è¾¼ã¿æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""

    def test_simple_data_deserialization(self):
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        original_data = {
            "integer": 42,
            "float_val": 3.14159,
            "boolean": True,
            "string": "Hello HDF5",
            "none_value": None,
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            # æ›¸ãè¾¼ã¿
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            # èª­ã¿è¾¼ã¿
            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["integer"] == 42
            assert abs(restored_data["float_val"] - 3.14159) < 1e-6
            assert restored_data["boolean"] is True
            assert restored_data["string"] == "Hello HDF5"
            assert restored_data["none_value"] is None
        finally:
            tmp_path.unlink()

    def test_numpy_array_deserialization(self):
        """NumPyé…åˆ—ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        original_data = {
            "int_array": np.array([1, 2, 3, 4, 5]),
            "float_array": np.array([1.1, 2.2, 3.3]),
            "2d_array": np.array([[1, 2], [3, 4]]),
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            np.testing.assert_array_equal(restored_data["int_array"], [1, 2, 3, 4, 5])
            np.testing.assert_array_almost_equal(restored_data["float_array"], [1.1, 2.2, 3.3])
            np.testing.assert_array_equal(restored_data["2d_array"], [[1, 2], [3, 4]])
        finally:
            tmp_path.unlink()

    def test_torch_tensor_deserialization(self):
        """PyTorchãƒ†ãƒ³ã‚½ãƒ«ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        original_data = {
            "tensor_1d": torch.tensor([1.0, 2.0, 3.0]),
            "tensor_2d": torch.tensor([[1, 2], [3, 4]]),
            "tensor_float32": torch.tensor([1.0, 2.0], dtype=torch.float32),
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦å¾©å…ƒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert isinstance(restored_data["tensor_1d"], torch.Tensor)
            assert isinstance(restored_data["tensor_2d"], torch.Tensor)
            torch.testing.assert_close(restored_data["tensor_1d"], torch.tensor([1.0, 2.0, 3.0]))
            torch.testing.assert_close(restored_data["tensor_2d"], torch.tensor([[1, 2], [3, 4]]))
        finally:
            tmp_path.unlink()

    def test_list_deserialization(self):
        """ãƒªã‚¹ãƒˆ/ã‚¿ãƒ—ãƒ«ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        original_data = {
            "empty_list": [],
            "number_list": [1, 2, 3, 4, 5],
            "string_list": ["apple", "banana", "cherry"],
            "mixed_list": [1, "hello", 3.14],
            "nested_list": [[1, 2], [3, 4]],
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["empty_list"] == []
            np.testing.assert_array_equal(restored_data["number_list"], [1, 2, 3, 4, 5])
            assert restored_data["string_list"] == ["apple", "banana", "cherry"]
            assert len(restored_data["mixed_list"]) == 3
            assert restored_data["mixed_list"][0] == 1
            assert restored_data["mixed_list"][1] == "hello"
            assert abs(restored_data["mixed_list"][2] - 3.14) < 1e-6
        finally:
            tmp_path.unlink()

    def test_bytes_deserialization(self):
        """ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        original_data = {
            "single_bytes": b"hello world",
            "bytearray_data": bytearray(b"test data"),
            "bytes_list": [b"first", b"second", b"third"],
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["single_bytes"] == b"hello world"
            assert restored_data["bytearray_data"] == b"test data"
            assert restored_data["bytes_list"] == [b"first", b"second", b"third"]
        finally:
            tmp_path.unlink()

    def test_nested_dict_deserialization(self):
        """ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã®ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³"""
        original_data = {
            "level1": {
                "level2": {
                    "level3": {"deep_value": 42, "deep_array": np.array([1, 2, 3])},
                },
                "sibling": "value",
            },
            "metadata": {"version": "1.0", "author": "test"},
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["level1"]["level2"]["level3"]["deep_value"] == 42
            np.testing.assert_array_equal(restored_data["level1"]["level2"]["level3"]["deep_array"], [1, 2, 3])
            assert restored_data["level1"]["sibling"] == "value"
            assert restored_data["metadata"]["version"] == "1.0"
        finally:
            tmp_path.unlink()


class TestRoundtrip:
    """å¾€å¾©å¤‰æ›ï¼ˆæ›¸ãè¾¼ã¿ â†’ èª­ã¿è¾¼ã¿ï¼‰ã®ãƒ†ã‚¹ãƒˆ"""

    def test_simple_roundtrip(self):
        """åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å‹ã®å¾€å¾©å¤‰æ›"""
        original_data = {
            "int": 42,
            "float": 3.14159,
            "str": "test string",
            "bool": True,
            "none": None,
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            # å¾€å¾©å¤‰æ›
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["int"] == original_data["int"]
            assert abs(restored_data["float"] - original_data["float"]) < 1e-6
            assert restored_data["str"] == original_data["str"]
            assert restored_data["bool"] == original_data["bool"]
            assert restored_data["none"] == original_data["none"]
        finally:
            tmp_path.unlink()

    def test_complex_structure_roundtrip(self):
        """è¤‡é›‘ãªæ§‹é€ ã®å¾€å¾©å¤‰æ›"""
        original_data = {
            "arrays": {
                "numpy_1d": np.array([1, 2, 3, 4]),
                "numpy_2d": np.array([[1, 2], [3, 4]]),
                "torch_tensor": torch.tensor([1.0, 2.0, 3.0]),
            },
            "lists": {
                "numbers": [1, 2, 3, 4, 5],
                "strings": ["a", "b", "c"],
                "empty": [],
                "mixed": [1, "hello", 3.14, True],
            },
            "bytes_data": {"single": b"test", "list": [b"a", b"b", b"c"]},
            "metadata": {"version": 1.0, "debug": True},
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            # NumPyé…åˆ—
            np.testing.assert_array_equal(restored_data["arrays"]["numpy_1d"], original_data["arrays"]["numpy_1d"])
            np.testing.assert_array_equal(restored_data["arrays"]["numpy_2d"], original_data["arrays"]["numpy_2d"])

            # PyTorchãƒ†ãƒ³ã‚½ãƒ«
            torch.testing.assert_close(restored_data["arrays"]["torch_tensor"], original_data["arrays"]["torch_tensor"])

            # ãƒªã‚¹ãƒˆï¼ˆNumPyé…åˆ—ã¨ã—ã¦å¾©å…ƒã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã®ã§é©åˆ‡ã«æ¯”è¼ƒï¼‰
            np.testing.assert_array_equal(restored_data["lists"]["numbers"], original_data["lists"]["numbers"])
            assert restored_data["lists"]["strings"] == original_data["lists"]["strings"]
            assert restored_data["lists"]["empty"] == original_data["lists"]["empty"]

            # ãƒã‚¤ãƒˆ
            assert restored_data["bytes_data"]["single"] == original_data["bytes_data"]["single"]
            assert restored_data["bytes_data"]["list"] == original_data["bytes_data"]["list"]

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            assert restored_data["metadata"]["version"] == original_data["metadata"]["version"]
            assert restored_data["metadata"]["debug"] == original_data["metadata"]["debug"]
        finally:
            tmp_path.unlink()

    def test_large_data_roundtrip(self):
        """å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã®å¾€å¾©å¤‰æ›"""
        # å¤§ããªé…åˆ—ãƒ‡ãƒ¼ã‚¿
        large_array = np.random.rand(1000, 100)
        large_tensor = torch.randn(500, 200)

        original_data = {
            "large_numpy": large_array,
            "large_torch": large_tensor,
            "large_list": list(range(10000)),
            "metadata": {"size": "large", "elements": 10000},
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(original_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            # å¤§ããªé…åˆ—ã®å½¢çŠ¶ã¨ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèª
            assert restored_data["large_numpy"].shape == (1000, 100)
            assert restored_data["large_torch"].shape == torch.Size([500, 200])
            assert len(restored_data["large_list"]) == 10000
            assert restored_data["large_list"][0] == 0
            assert restored_data["large_list"][-1] == 9999

            # å†…å®¹ã®ä¸€éƒ¨ã‚’ã‚µãƒ³ãƒ—ãƒ«ãƒã‚§ãƒƒã‚¯
            np.testing.assert_array_almost_equal(restored_data["large_numpy"][:5, :5], large_array[:5, :5])
            torch.testing.assert_close(restored_data["large_torch"][:5, :5], large_tensor[:5, :5])
        finally:
            tmp_path.unlink()


class TestEdgeCases:
    """ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãƒ»åˆ¶é™äº‹é …ãƒ»ç‰¹æ®Šã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_invalid_hdf5_keys(self):
        """HDF5ã§ç„¡åŠ¹ãªã‚­ãƒ¼ã§ã®ã‚¨ãƒ©ãƒ¼"""
        data = {"invalid/key": "value"}  # '/'ã‚’å«ã‚€ã‚­ãƒ¼

        with pytest.raises(ValueError, match="HDF5 key cannot contain"):
            with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
                tmp_path = Path(tmp.name)
            try:
                with h5py.File(tmp_path, "w") as f:
                    interface = Hdf5Storage(data)
                    interface.to_hdf5_group(f)
            finally:
                tmp_path.unlink()

    def test_unsupported_types(self):
        """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å‹ã§ã®ã‚¨ãƒ©ãƒ¼"""

        class CustomClass:
            def __init__(self, value):
                self.value = value

        data = {"custom_object": CustomClass(42)}

        with pytest.raises(TypeError, match="Unsupported type"):
            with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
                tmp_path = Path(tmp.name)
            try:
                with h5py.File(tmp_path, "w") as f:
                    interface = Hdf5Storage(data)
                    interface.to_hdf5_group(f)
            finally:
                tmp_path.unlink()

    def test_empty_data(self):
        """ç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ã®å‹•ä½œ"""
        empty_data: Dict[str, any] = {}

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(empty_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data == {}
        finally:
            tmp_path.unlink()

    def test_extreme_values(self):
        """æ¥µç«¯ãªå€¤ã§ã®å‹•ä½œ"""
        extreme_data = {
            "very_large_int": 2**63 - 1,
            "very_small_int": -(2**63),
            "very_large_float": 1e308,
            "very_small_float": 1e-308,
            "inf_value": float("inf"),
            "neg_inf_value": float("-inf"),
            "nan_value": float("nan"),
            "empty_string": "",
            "unicode_string": "ã“ã‚“ã«ã¡ã¯ä¸–ç•ŒğŸŒ",
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(extreme_data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["very_large_int"] == 2**63 - 1
            assert restored_data["very_small_int"] == -(2**63)
            assert restored_data["inf_value"] == float("inf")
            assert restored_data["neg_inf_value"] == float("-inf")
            assert np.isnan(restored_data["nan_value"])
            assert restored_data["empty_string"] == ""
            assert restored_data["unicode_string"] == "ã“ã‚“ã«ã¡ã¯ä¸–ç•ŒğŸŒ"
        finally:
            tmp_path.unlink()

    def test_data_type_preservation(self):
        """ãƒ‡ãƒ¼ã‚¿å‹ã®ä¿æŒãƒ†ã‚¹ãƒˆ"""
        data = {
            "int8": np.int8(127),
            "int16": np.int16(32767),
            "int32": np.int32(2147483647),
            "int64": np.int64(9223372036854775807),
            "uint8": np.uint8(255),
            "float32": np.float32(3.14159),
            "float64": np.float64(2.718281828),
            # complexæ•°å€¤ã¯ç¾åœ¨ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„
        }

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            # åŸºæœ¬çš„ãªå€¤ã®ç¢ºèªï¼ˆå‹ã¯å®Œå…¨ã«ä¿æŒã•ã‚Œãªã„å ´åˆã‚‚ã‚ã‚‹ãŒã€å€¤ã¯ä¿æŒã•ã‚Œã‚‹ï¼‰
            assert restored_data["int8"] == 127
            assert restored_data["int16"] == 32767
            assert restored_data["int32"] == 2147483647
            assert abs(restored_data["float32"] - 3.14159) < 1e-5
            assert abs(restored_data["float64"] - 2.718281828) < 1e-10
        finally:
            tmp_path.unlink()

    def test_non_dict_top_level_error(self):
        """ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãŒè¾æ›¸ã§ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼"""
        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            # æ‰‹å‹•ã§HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã«éè¾æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã¿ã€ã‚°ãƒ«ãƒ¼ãƒ—ãªã—ï¼‰
            with h5py.File(tmp_path, "w") as f:
                f.create_dataset("not_a_dict", data="this is not a dict structure")
                # ã‚°ãƒ«ãƒ¼ãƒ—ãŒãªã„å ´åˆã¯TypeErrorãŒç™ºç”Ÿã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€
                # ã“ã®ãƒ†ã‚¹ãƒˆã¯å®Ÿéš›ã®å‹•ä½œã‚’ç¢ºèª

            with h5py.File(tmp_path, "r") as f:
                # å®Ÿéš›ã®å‹•ä½œã‚’ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã‹ã©ã†ã‹ï¼‰
                try:
                    result = Hdf5Storage.from_hdf5_group(f)
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„å ´åˆã¯ã€çµæœã‚’ç¢ºèª
                    assert isinstance(result._source, dict)
                except TypeError as e:
                    assert "Top-level object must be a dict" in str(e)
        finally:
            tmp_path.unlink()

    def test_memory_efficiency(self):
        """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ€§ã®ç¢ºèªï¼ˆå¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ï¼‰"""
        # éå¸¸ã«å¤§ããªãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒ†ã‚¹ãƒˆï¼‰
        huge_array = np.zeros((10000, 1000), dtype=np.float32)  # ç´„40MB
        data = {"huge_data": huge_array, "metadata": {"size": "huge"}}

        with tempfile.NamedTemporaryFile(suffix=".h5", delete=False) as tmp:
            tmp_path = Path(tmp.name)

        try:
            # æ›¸ãè¾¼ã¿
            with h5py.File(tmp_path, "w") as f:
                interface = Hdf5Storage(data)
                interface.to_hdf5_group(f)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
            file_size = tmp_path.stat().st_size
            assert file_size > 1024 * 1024  # å°‘ãªãã¨ã‚‚1MBä»¥ä¸Š

            # èª­ã¿è¾¼ã¿
            with h5py.File(tmp_path, "r") as f:
                restored_interface = Hdf5Storage.from_hdf5_group(f)
                restored_data = restored_interface._source

            assert restored_data["huge_data"].shape == (10000, 1000)
            assert restored_data["metadata"]["size"] == "huge"
        finally:
            tmp_path.unlink()


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
